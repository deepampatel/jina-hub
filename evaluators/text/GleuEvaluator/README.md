# GleuEvaluator

The GLEU metric is a variant of BLEU proposed for evaluating grammatical error corrections using n-gram overlap with a set of reference sentences, as opposed to precision/recall of specific annotated errors. A perfect match will score 1.0 and a complete mismatch will score 0.0
